Clasificador BiomÃ©dico Multietiqueta (Cardio / Neuro / Hepatorrenal / Onco)

Demo (Hugging Face): https://huggingface.co/spaces/jennifersalazarduke/clasificador-biomedicoTECH_SPHERE

Storytelling (Notion): https://humorous-polyester-33a.notion.site/Challenge-de-Clasificaci-n-Biom-dica-con-IA-25a30d9b1a1180dba80de926852cc7fd?pvs=74

Repositorio pÃºblico (GitHub): https://github.com/SalazarDukeImpactHub/tech-sphere-clasificador-biomedico-multietiqueta

TL;DR: Este proyecto clasifica artÃ­culos mÃ©dicos (usando tÃ­tulo + abstract) en una o varias Ã¡reas: Cardiovascular, NeurolÃ³gico, Hepatorrenal, OncolÃ³gico. El modelo principal usa TF-IDF (palabra+carÃ¡cter) + RegresiÃ³n LogÃ­stica OVR y alcanza F1 ponderado â‰ˆ 0.905. Incluye: cuaderno de entrenamiento, artefactos del modelo listos para producciÃ³n, API REST y demo web. AdemÃ¡s, se aporta un dashboard V0 para comunicar resultados y enlaces a un storytelling en Notion.

ğŸŒŸ QuÃ© hace y para quiÃ©n es

QuÃ© hace: Lee title+abstract, calcula probabilidades por tema y asigna mÃºltiples etiquetas cuando corresponde.

Para quiÃ©n: Perfiles junior/intermedios en datos/IA, equipos clÃ­nicos o de producto que requieran priorizar lectura de literatura biomÃ©dica.

ğŸš€ Resultados (hold-out 20%)

F1 ponderado â‰ˆ 0.905

MÃ©tricas por tema (aprox.):

Cardiovascular 0.92 Â· NeurolÃ³gico 0.90 Â· Hepatorrenal 0.90 Â· OncolÃ³gico 0.88

Umbrales por clase (producciÃ³n): [0.43, 0.58, 0.48, 0.50]

Nota: el sistema nunca devuelve vacÃ­o: si ninguna prob supera su umbral, usa Top-1 como respaldo.

ğŸ§  Enfoque del modelo (breve y entendible)

Texto â†’ nÃºmeros: TF-IDF por palabra (1â€“2) y por carÃ¡cter (3â€“5) para captar tÃ©rminos y abreviaturas.

Aprendizaje: RegresiÃ³n LogÃ­stica en esquema One-Vs-Rest (una por tema).

DecisiÃ³n: umbrales por clase afinados para maximizar F1 ponderado.

Multietiqueta: puede activar varias Ã¡reas si el artÃ­culo es mixto.

ğŸ—‚ï¸ Estructura del repositorio
tech-sphere-clasificador-biomedico-multietiqueta/
â”œâ”€ data/                       # dataset (ej. challenge_data-18-ago.csv)*
â”œâ”€ models_final/               # artefactos de producciÃ³n
â”‚  â”œâ”€ pipeline.joblib          # vectorizadores + clasificador
â”‚  â””â”€ meta.json                # labels, thresholds, engine
â”œâ”€ notebooks/
â”‚  â””â”€ intento1.ipynb           # cuaderno final organizado (entrenamiento/validaciÃ³n)
â”œâ”€ src/
â”‚  â”œâ”€ app.py                   # API REST (FastAPI)
â”‚  â””â”€ streamlit_app.py         # demo local/Space
â”œâ”€ v0/                         # prompts y recursos de visualizaciÃ³n (V0)
â”œâ”€ reports_env/                # environment.yml, requirements.txt, reportes de entorno
â”œâ”€ README.md
â””â”€ .gitignore


* Si el dataset es sensible/privado, no subir a GitHub (.gitignore).

ğŸ”— Enlaces importantes

Demo en vivo (Hugging Face Space): abre el formulario, pega tÃ­tulo+abstract y visualiza etiquetas y barras de confianza.
https://huggingface.co/spaces/jennifersalazarduke/clasificador-biomedicoTECH_SPHERE

Storytelling del proyecto (Notion): relato amigable del reto, decisiones y resultados.
https://humorous-polyester-33a.notion.site/Challenge-de-Clasificaci-n-Biom-dica-con-IA-25a30d9b1a1180dba80de926852cc7fd?pvs=74

Repositorio pÃºblico (GitHub): cÃ³digo fuente, artefactos y documentaciÃ³n.
https://github.com/SalazarDukeImpactHub/tech-sphere-clasificador-biomedico-multietiqueta

ğŸ§ª Reproducir localmente (entorno biomed-ml)

Recomendado: Python 3.10. Estos pasos fueron probados en Anaconda Prompt (Windows).

# 1) Crear/activar entorno
conda create -n biomed-ml python=3.10 -y
conda activate biomed-ml
python -m pip install --upgrade pip

# 2) Instalar dependencias
python -m pip install -r requirements.txt
# (si no existe, instalar mÃ­nimas)
# python -m pip install scikit-learn==1.7.1 numpy pandas joblib fastapi uvicorn streamlit

# 3) Verificar versiones clave (opcional)
python -c "import sklearn,streamlit,sys; print('sklearn', sklearn.__version__, '| streamlit', streamlit.__version__, '| py', sys.version)"


Entrenamiento y validaciÃ³n
Abre notebooks/intento1.ipynb, selecciona el kernel Python (biomed-ml) y ejecuta.
Al finalizar, se generan models_final/pipeline.joblib y models_final/meta.json.

ğŸ”Œ API REST (FastAPI)

Arranca la API que sirve las predicciones (JSON):

# en la raÃ­z del repo
set MODEL_DIR=models_final
uvicorn src.app:app --host 0.0.0.0 --port 8000


Endpoints

GET /health â†’ estado, labels, thresholds

POST /predict â†’ body:

{ "title": "string", "abstract": "string", "top_k": 0, "fallback": true }


Modo umbrales (top_k=0) o Top-K (top_k>0).

â–¶ï¸ Demo web (Streamlit)

Ejecuta localmente la demo (la misma que se usa en el Space):

streamlit run src/streamlit_app.py

ğŸ“Š VisualizaciÃ³n con V0 (bonus)

En v0/ encontrarÃ¡s prompts para crear un dashboard de una sola pÃ¡gina (KPIs, mÃ©tricas por tema con barras de colores diferenciados, y panel de errores por tema).
El dashboard incluye botones a:

Probar la demo (Hugging Face)

Storytelling (Notion)

CÃ³digo (GitHub)

Pensado para comunicar resultados a pÃºblico no tÃ©cnico, con tooltips claros y sin jerga.

âœ… Checklist de entrega

 Cuaderno final organizado (notebooks/intento1.ipynb)

 Modelo listo para servir (models_final/)

 API REST (src/app.py)

 Demo web (src/streamlit_app.py) y Space pÃºblico

 V0 dashboard (prompts y recursos)

 Reportes de entorno (reports_env/) para reproducibilidad

ğŸ”’ Consideraciones y lÃ­mites

No es un dispositivo mÃ©dico; requiere revisiÃ³n humana.

Textos muy cortos pueden ser ambiguos.

Para mayor recall en clases minoritarias, considerar BioBERT/ClinicalBERT (pipeline alterno).

ğŸ‘©â€ğŸ’» AutorÃ­a

Jennifer Salazar Duke â€” Salazar Duke Impact Hub

Â¿Preguntas o mejoras? Abre un Issue o un Pull Request en este repositorio.
